task:
  llmeval
data_path:
  ./agentverse/tasks/llm_eval/data/faireval/preprocessed_data/test.json
output_dir:
  ./outputs/llm_eval/multi_role/faireval/four_turns_simultaneous/four_different_role
prompts:
  prompt: &prompt |-
    [Question]
    ${source_text}
    [The Start of Assistant 1’s Answer]
    ${compared_text_one}
    [The End of Assistant 1’s Answer]
    [System]
    Ti chiediamo di fornire un feedback sulla prestazione di un assistente AI in risposta alla domanda dell'utente mostrata sopra.
    Considera l'utilità, la pertinenza, la correttezza e il livello di dettaglio della risposta.
    Ci sono altri giudici assegnati allo stesso compito: è tua responsabilità discutere con loro e pensare criticamente prima di esprimere il tuo giudizio finale.
    L'assistente riceverà un punteggio complessivo da 1 a 10, dove un punteggio più alto indica una prestazione migliore.
    Rispondi solo ed esclusivamente in italiano. Evita qualsiasi parola in inglese.

    ${role_description}

    È il tuo turno, parla in modo breve e chiaro, ${agent_name} !

    ${chat_history}


environment:
  env_type: llm_eval
  max_turns: 5
  rule:
    order:
      type: concurrent
    visibility:
      type: all
    selector:
      type: basic
    updater:
      type: basic
    describer:
      type: basic

agents:
  -
    agent_type: llm_eval_multi_con
    name: General Public
    final_prompt_to_use: |-
      Valuta la risposta dell'assistente in modo oggettivo e critico, evitando qualsiasi pregiudizio.
      Ricorda che non sei obbligato a fornire lo stesso voto degli altri giudici.

      Rispondi **solo** con il seguente formato:
      Evaluation evidence: [spiegazione in italiano]
      The score of Assistant 1: [score only]

      Non inserire spazi inutili nella risposta: solo uno spazio tra una parola e l'altra. Evita righe vuote, doppi spazi o ritorni a capo non necessari.
    role_description: |-
      Sei il Pubblico Generico. Sei interessato alla storia e vuoi aggiornamenti sull'indagine. Esprimi un giudizio critico in autonomia.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gemma2-9b-it"
      llm_type: gemma2-9b-it
      temperature: 0
      max_tokens: 192
  -
    agent_type: llm_eval_multi_con
    name: Critic
    final_prompt_to_use: |-
      Valuta la risposta dell'assistente in modo oggettivo e critico, evitando qualsiasi pregiudizio.
      Ricorda che non sei obbligato a fornire lo stesso voto degli altri giudici.

      Rispondi **solo** con il seguente formato:
      Evaluation evidence: [spiegazione in italiano]
      The score of Assistant 1: [score only]

      Non inserire spazi inutili nella risposta: solo uno spazio tra una parola e l'altra. Evita righe vuote, doppi spazi o ritorni a capo non necessari.
    role_description: |-
      Sei il Critico. Valuti la fluidità, la chiarezza e la scelta delle parole. Metti in discussione i giudizi altrui se necessario.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gemma2-9b-it"
      llm_type: gemma2-9b-it
      temperature: 0
      max_tokens: 192
  -
    agent_type: llm_eval_multi_con
    name: News Author
    final_prompt_to_use: |-
      Valuta la risposta dell'assistente in modo oggettivo e critico, evitando qualsiasi pregiudizio.
      Ricorda che non sei obbligato a fornire lo stesso voto degli altri giudici.

      Rispondi **solo** con il seguente formato:
      Evaluation evidence: [spiegazione in italiano]
      The score of Assistant 1: [score only]

      Non inserire spazi inutili nella risposta: solo uno spazio tra una parola e l'altra. Evita righe vuote, doppi spazi o ritorni a capo non necessari.
    role_description: |-
      Sei l'Autore di Notizie. Valuti la coerenza con l'articolo originale. Aiuta gli altri a stabilire quale risposta è migliore.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gemma2-9b-it"
      llm_type: gemma2-9b-it
      temperature: 0
      max_tokens: 192
  -
    agent_type: llm_eval_multi_con
    name: Psychologist
    final_prompt_to_use: |-
      Valuta la risposta dell'assistente in modo oggettivo e critico, evitando qualsiasi pregiudizio.
      Ricorda che non sei obbligato a fornire lo stesso voto degli altri giudici.

      Rispondi **solo** con il seguente formato:
      Evaluation evidence: [spiegazione in italiano]
      The score of Assistant 1: [score only]

      Non inserire spazi inutili nella risposta: solo uno spazio tra una parola e l'altra. Evita righe vuote, doppi spazi o ritorni a capo non necessari.
    role_description: |-
      Sei lo Psicologo. Studi il comportamento umano e valuti la risposta in base a comprensione e impatto sull'utente.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gemma2-9b-it"
      llm_type: gemma2-9b-it
      temperature: 0
      max_tokens: 192
  # -
  #   agent_type: llm_eval_multi
  #   name: Scientist
  #   final_prompt_to_use: |-
  #     Please first provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.
  #     Then, output one lines indicating the scores for Assistant 1.Response always in italian.

  #     Remember that you are not required to output the same value as other referees !
  #     Output with the following format strictly:
  #     Evaluation evidence: [your explanation here]
  #     The score of Assistant 1: [score only]
  #   role_description: |-
  #     You are Scientist, one of the referees in this task. You are a professional engaged in systematic study who possesses a strong background in the scientific method, critical thinking, and problem-solving abilities. Please help other people determine which response is the better one.
  #   memory:
  #     memory_type: chat_history
  #   memory_manipulator:
  #     memory_manipulator_type: basic
  #   prompt_template: *prompt
  #   llm:
  #     model: "deepseek-r1-distill-llama-70b"
  #     llm_type: deepseek-r1-distill-llama-70b
  #     temperature: 0
  #     max_tokens: 512

tools: ~